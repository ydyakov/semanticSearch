<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Slide 9 - Neural query</title>
    <link rel="stylesheet" href="style.css">
    <script src="main.js" defer></script>
</head>
<body data-slide="11">
    <div class="content">
        <main class="main-section">
            <div class="slide-content" style="min-width: 1200px;">
                <h1 style="margin-bottom: 60px; margin-top:-50px;" ">Text Embedding Models (Hugging Face)</h1>

                <table class="compare-table">
                    <thead>
                        <tr>
                            <th>Model</th>
                            <th style="min-width: 120px;">Vector Size</th>
                            <th>Strengths</th>
                            <th>Limitations</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><code>sentence-transformers/all-MiniLM-L6-v2</code></td>
                            <td>384</td>
                            <td>Fast, lightweight, good general semantic similarity</td>
                            <td>Lower accuracy on complex semantic tasks</td>
                        </tr>
                        <tr>
                            <td><code>sentence-transformers/paraphrase-MiniLM-L12-v2</code></td>
                            <td>384</td>
                            <td>Good for semantic search, paraphrase detection</td>
                            <td>Moderate speed</td>
                        </tr>
                        <tr>
                            <td><code>sentence-transformers/all-mpnet-base-v2</code></td>
                            <td>768</td>
                            <td>High accuracy on semantic similarity tasks</td>
                            <td>Heavier, slower than MiniLM</td>
                        </tr>
                        <tr>
                            <td><code>sentence-transformers/multi-qa-MiniLM-L6-cos-v1</code></td>
                            <td>384</td>
                            <td>Optimized for QA retrieval tasks</td>
                            <td>Narrower domain than general models</td>
                        </tr>
                        <tr>
                            <td><code>sentence-transformers/all-distilroberta-v1</code></td>
                            <td>768</td>
                            <td>Balanced model with good general-purpose embeddings</td>
                            <td>Not as lightweight as MiniLM</td>
                        </tr>
                        <tr>
                            <td><code>sentence-transformers/distiluse-base-multilingual-cased-v1</code></td>
                            <td>512</td>
                            <td>Multilingual support (15+ languages), good for cross-language search</td>
                            <td>Slightly slower than English-only models</td>
                        </tr>
                        <tr>
                            <td><code>sentence-transformers/paraphrase-multilingual-mpnet-base-v2</code></td>
                            <td>768</td>
                            <td>Multilingual, strong performance across languages and tasks</td>
                            <td>Large size, requires more resources</td>
                        </tr>
                        <tr>
                            <td><code>sentence-transformers/MiniLM-L3-v2</code></td>
                            <td>384</td>
                            <td>Even smaller and faster variant, efficient on low-resource setups</td>
                            <td>Lower semantic accuracy compared to L6/L12</td>
                        </tr>
                    </tbody>
                </table>

                <p class="note">
                    ⚡ Choosing the right embedding model depends on the trade-off between <b>accuracy</b>, <b>speed</b>, and <b>vector size</b>.
                </p>

                <pre style="display:none;" id="codeX">PUT _cluster/settings
{
   "persistent":{
     "plugins.ml_commons.only_run_on_ml_node": false
   }
}

POST /_plugins/_ml/models/_upload
{
    "name": "huggingface/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
    "version": "1.0.1",
    "model_format": "TORCH_SCRIPT"
}

 
GET /_plugins/_ml/tasks/task-id


POST /_plugins/_ml/models/model-id/_load

GET /_plugins/_ml/tasks/task-id

</pre>

            </div>
        </main>

        <footer class="footer">
            <div class="footer-left">
                <span>Yordan Dyakov - DevTalks 2026</span>
            </div>
            <div class="footer-right">
                <a href="slide10.html" class="nav-btn">⬅</a>
                <a href="slide12.html" class="nav-btn">➡</a>
            </div>
        </footer>
    </div>
</body>
</html>
